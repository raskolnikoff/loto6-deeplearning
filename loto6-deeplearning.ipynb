{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 0. Initial Setup\n",
    "#===============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Mount Google Drive (if needed)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "model_path = \"/content/drive/MyDrive/loto6_model.keras\"\n",
    "\n",
    "# Loto6 data automatic retrieval\n",
    "LOTO6_DATA_URL = \"https://loto6.thekyo.jp/data/loto6.csv\"\n",
    "df = pd.read_csv(LOTO6_DATA_URL, encoding=\"shift-jis\")\n",
    "\n",
    "# Extract only the number columns (1st to 6th numbers)\n",
    "loto_number_cols = [f\"第{i}数字\" for i in range(1, 7)]\n",
    "df = df[loto_number_cols]\n",
    "df = df.dropna(axis=1, how='any')\n",
    "numbers = df.astype(int).values\n",
    "print(f\"Number of data acquired: {len(numbers)}\")\n"
   ],
   "id": "c32e49a833c71098"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Feature Engineering\n",
    "#===============================\n",
    "window_length = 7\n",
    "\n",
    "# frequency (cumulative occurrence count)\n",
    "frequency = np.zeros((len(df), 43))\n",
    "counter = np.zeros(43)\n",
    "for i, row in enumerate(numbers):\n",
    "    for n in row:\n",
    "        counter[n-1] += 1\n",
    "    frequency[i] = counter.copy()\n",
    "\n",
    "# gap (number of draws since last appearance)\n",
    "last_seen = [-1]*43\n",
    "gap = np.zeros((len(df), 43))\n",
    "for i, row in enumerate(numbers):\n",
    "    for n in range(1,44):\n",
    "        if n in row:\n",
    "            last_seen[n-1] = i\n",
    "        gap[i,n-1] = i - last_seen[n-1] if last_seen[n-1] != -1 else 0\n",
    "\n",
    "# Combine features\n",
    "full_features = np.concatenate([\n",
    "    numbers/43,                          # normalized main numbers\n",
    "    frequency/np.max(frequency),         # frequency\n",
    "    gap/np.max(gap)                      # gap\n",
    "], axis=1)\n",
    "\n",
    "# Generate sliding windows\n",
    "X, y = [], []\n",
    "for i in range(len(full_features)-window_length):\n",
    "    X.append(full_features[i:i+window_length])\n",
    "    label = np.zeros(43)\n",
    "    for n in numbers[i+window_length]:\n",
    "        label[n-1] = 1\n",
    "    y.append(label)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n"
   ],
   "id": "f4bb2bd0148278a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 2. Model construction and reuse\n",
    "#===============================\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model = load_model(model_path)\n",
    "    print(\"Loaded existing model.\")\n",
    "        # Fine-tune on the latest data with a small learning rate, then save\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='mse')\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=50, batch_size=32,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(model_path)\n",
    "    print(\"Fine-tuned existing model and saved.\")\n",
    "else:\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(128, return_sequences=True,\n",
    "                           input_shape=(window_length, X.shape[2]),\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))),\n",
    "        Dropout(0.3),\n",
    "        Bidirectional(LSTM(128, return_sequences=True,\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))),\n",
    "        Dropout(0.3),\n",
    "        Bidirectional(LSTM(128, return_sequences=True,\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))),\n",
    "        Dropout(0.3),\n",
    "        Bidirectional(LSTM(128, return_sequences=False,\n",
    "                           kernel_regularizer=regularizers.l2(1e-4))),\n",
    "        Dropout(0.3),\n",
    "        Dense(43, activation='linear')  # Regression output\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        epochs=1500, batch_size=32,\n",
    "        validation_data=(x_test, y_test),\n",
    "        verbose=1\n",
    "    )\n",
    "    model.save(model_path)\n",
    "    print(\"Trained and saved new model.\")\n"
   ],
   "id": "3d80d246c2499c98"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot learning curve\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Learning Curve (MSE Loss)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "5b1bcd198bfa003c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. Monte Carlo Dropout prediction\n",
    "#===============================\n",
    "@tf.function\n",
    "def monte_carlo_predict(model, x, T=30):\n",
    "    return tf.stack([model(x, training=True)[0] for _ in range(T)])\n",
    "\n",
    "x_future = X[-1:]\n",
    "predictions = monte_carlo_predict(model, x_future, T=30).numpy()\n",
    "mean_scores = predictions.mean(axis=0)\n",
    "std_scores = predictions.std(axis=0)\n",
    "\n",
    "# Frequent top 15 numbers\n",
    "all_numbers = []\n",
    "for pred in predictions:\n",
    "    top6 = np.argsort(pred)[-6:]+1\n",
    "    all_numbers.extend(top6.tolist())\n",
    "top15 = [num for num,_ in Counter(all_numbers).most_common(15)]\n",
    "print(\"Frequent TOP15:\", sorted(top15))\n",
    "\n",
    "# Representative 6-number prediction (confidence-based)\n",
    "final_main_numbers = np.sort(np.argsort(mean_scores)[-6:]+1)\n",
    "print(\"Representative prediction:\", final_main_numbers)\n",
    "\n",
    "# Monte Carlo variation candidates\n",
    "unique_sets = []\n",
    "for pred in predictions:\n",
    "    s = tuple(np.sort(np.argsort(pred)[-6:]+1))\n",
    "    if s not in unique_sets:\n",
    "        unique_sets.append(s)\n",
    "print(\"Monte Carlo variation candidates:\", unique_sets[:5])"
   ],
   "id": "fb8bfdc5823a8709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate 3 subset tickets from Monte Carlo candidates\n",
    "# Representative prediction is stored as final_main_numbers\n",
    "num_subsets = 3\n",
    "\n",
    "# Extract unique top 6-number sets from Monte Carlo output\n",
    "all_candidate_sets = []\n",
    "for pred in predictions:\n",
    "    s = tuple(np.sort(np.argsort(pred)[-6:]+1))\n",
    "    if s not in all_candidate_sets:\n",
    "        all_candidate_sets.append(s)\n",
    "\n",
    "# Exclude representative set and select top 3 subsets\n",
    "subsets_for_purchase = []\n",
    "for s in all_candidate_sets:\n",
    "    if tuple(final_main_numbers) != s:\n",
    "        subsets_for_purchase.append(s)\n",
    "    if len(subsets_for_purchase) >= num_subsets:\n",
    "        break\n",
    "\n",
    "print(\"Representative prediction:\", final_main_numbers)\n",
    "print(\"3 subset tickets:\", subsets_for_purchase)"
   ],
   "id": "dd11e9196f85c7d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 4. Visualization\n",
    "#===============================\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(np.arange(1,44), mean_scores, yerr=std_scores, capsize=3)\n",
    "plt.title(\"Prediction score distribution (mean ± std)\")\n",
    "plt.xlabel(\"Number\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.show()"
   ],
   "id": "36141dedc482993"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
